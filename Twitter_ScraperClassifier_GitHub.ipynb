{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Web Scraper and Text Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: Chandana Karunaratne\n",
    "#### Date: 9 April 2020\n",
    "#### Description: This code does the following:\n",
    "#### i) Collects the n most recent tweets for a specific hashtag during a specific period and saves them to a Pandas dataframe\n",
    "#### ii) Classifies each tweet based on sentiment (whether it is most likely to be positive or negative)\n",
    "#### iii) Classifies each tweet based on thematic area (the most likely category it belongs to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, friend\n"
     ]
    }
   ],
   "source": [
    "print \"hello, friend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pattern\n",
    "from pattern.en import sentiment\n",
    "from pattern.en import mood, modality\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Twitter Web Scraper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source: https://www.earthdatascience.org/courses/earth-analytics-python/using-apis-natural-language-processing-twitter/get-and-use-twitter-data-in-python/\n",
    "\n",
    "# Specify the variables that contain the user credentials to access Twitter API:\n",
    "\n",
    "# Note: These credentials below need to be updated occassionally\n",
    "\n",
    "access_token = \"XXXXXXXXXXXXXXXXXXXX\"\n",
    "access_token_secret = \"XXXXXXXXXXXXXXXXXXXX\"\n",
    "consumer_key = \"XXXXXXXXXXXXXXXXXXXX\"\n",
    "consumer_secret = \"XXXXXXXXXXXXXXXXXXXX\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify the authentication parameters using the variables specified above:\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the search term and the date_since date as variables:\n",
    "\n",
    "search_words = \"#coronavirus\"\n",
    "\n",
    "date_since = \"2019-12-01\"\n",
    "\n",
    "# Remove retweets:\n",
    "\n",
    "search_words = search_words + \" -filter:retweets\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Collect n most recent tweets from date_since date: \n",
    "\n",
    "n = 100\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       lang=\"en\",\n",
    "                       since=date_since,\n",
    "                       tweet_mode=\"extended\").items(n)\n",
    "\n",
    "# Save information about the tweet's user's name, screen name, datetime of tweet, user-specified location, number of followers,\n",
    "# and the tweet text:\n",
    "\n",
    "# For more attributes, see: https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/user-object\n",
    "\n",
    "user_data = [[tweet.user.name, \n",
    "              tweet.user.screen_name, \n",
    "              tweet.created_at, \n",
    "              tweet.user.location,\n",
    "              tweet.user.followers_count,\n",
    "              tweet.full_text] for tweet in tweets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter Name</th>\n",
       "      <th>Twitter Handle (username)</th>\n",
       "      <th>Date and Time</th>\n",
       "      <th>User-specified Location</th>\n",
       "      <th>Number of Followers</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael Coleman</td>\n",
       "      <td>Colemans1</td>\n",
       "      <td>2020-04-09 19:18:17</td>\n",
       "      <td>London</td>\n",
       "      <td>1198</td>\n",
       "      <td>BBC News - #Coronavirus: Ofcom formally probes David Icke TV interview https://t.co/dBc20GHUks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dan Currie</td>\n",
       "      <td>poeboston</td>\n",
       "      <td>2020-04-09 19:18:17</td>\n",
       "      <td>Boston</td>\n",
       "      <td>1623</td>\n",
       "      <td>The coronavirus outbreak is part of the climate change crisis @AJEnglish  https://t.co/PnCfwmRGFZ via @AJEnglish &amp;gt; #bospoli #mapoli #capitalism #publichealth #environment #climatechange #covid19 #coronavirus #pandemic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Twitter Name Twitter Handle (username)       Date and Time  \\\n",
       "0  Michael Coleman  Colemans1                2020-04-09 19:18:17   \n",
       "1  Dan Currie       poeboston                2020-04-09 19:18:17   \n",
       "\n",
       "  User-specified Location  Number of Followers  \\\n",
       "0  London                  1198                  \n",
       "1  Boston                  1623                  \n",
       "\n",
       "                                                                                                                                                                                                                          Tweet  \n",
       "0  BBC News - #Coronavirus: Ofcom formally probes David Icke TV interview https://t.co/dBc20GHUks                                                                                                                                \n",
       "1  The coronavirus outbreak is part of the climate change crisis @AJEnglish  https://t.co/PnCfwmRGFZ via @AJEnglish &gt; #bospoli #mapoli #capitalism #publichealth #environment #climatechange #covid19 #coronavirus #pandemic  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1) # Display all text in cells without truncation\n",
    "\n",
    "columns = ['Twitter Name', \n",
    "           'Twitter Handle (username)', \n",
    "           'Date and Time', \n",
    "           'User-specified Location', \n",
    "           'Number of Followers', \n",
    "           'Tweet']\n",
    "\n",
    "tweets_df = pd.DataFrame(data = user_data, columns = columns)\n",
    "\n",
    "tweets_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many tweets were collected:\n",
    "\n",
    "len(tweets_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sources:\n",
    "\n",
    "# 1) https://www.earthdatascience.org/courses/earth-analytics-python/using-apis-natural-language-processing-twitter/get-and-use-twitter-data-in-python/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Twitter Text Classifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) i) Cleaning the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove non-ASCII characters from 'Tweet' column in 'tweets_df' dataframe:\n",
    "\n",
    "# Sources: \n",
    "\n",
    "# i) https://www.quora.com/How-do-I-remove-non-ASCII-characters-e-g-%C3%90%C2%B1%C2%A7%E2%80%A2-%C2%B5%C2%B4%E2%80%A1%C5%BD%C2%AE%C2%BA%C3%8F%C6%92%C2%B6%C2%B9-from-texts-in-Panda%E2%80%99s-DataFrame-columns\n",
    "# ii) https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20\n",
    "\n",
    "# function to remove non-ASCII\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    return ''.join(i for i in text if ord(i)<128).encode('utf-8')\n",
    " \n",
    "tweets_df['Tweet'] = tweets_df['Tweet'].apply(remove_non_ascii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Punctuate each comment with a full-stop (\".\"):\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/20025882/append-string-to-the-start-of-each-value-in-a-said-column-of-a-pandas-dataframe\n",
    "\n",
    "counter = 0\n",
    "\n",
    "while counter < len(tweets_df):\n",
    "    if tweets_df['Tweet'][counter][-1] != '.':\n",
    "        tweets_df.loc[counter, 'Tweet'] = tweets_df['Tweet'][counter] + '.'\n",
    "    counter = counter + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) ii) Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the data in the 'Tweet' column of the 'content_df' dataframe to a list:\n",
    "\n",
    "tweets_list = tweets_df['Tweet'].tolist()\n",
    "# Create a list of sentiments for each student feedback comment:\n",
    "sent_list = []\n",
    "for i in tweets_list:\n",
    "    sent_list.append(sentiment(i)[0])\n",
    "    \n",
    "# Convert the above list into a dataframe:\n",
    "sent_df = pd.DataFrame({'Sentiment': sent_list})\n",
    "\n",
    "# Get the length of the above dataframe and then create a list of consecutive numbers to be used as the \"Tweet Number\":\n",
    "df_len = len(sent_df)\n",
    "my_list = range(0, df_len)\n",
    "idx = 0\n",
    "sent_df.insert(loc=idx, column='Tweet Number', value=my_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a column 'Tweet Number' to tweets_df so that the dataframe can be merged with sent_df:\n",
    "\n",
    "tweets_df.insert(loc=idx, column='Tweet Number', value=my_list)\n",
    "\n",
    "# Now, merge the two dataframes above, giving one dataframe with all information, including sentiment value for \n",
    "# each comment:\n",
    "\n",
    "# Source: https://chrisalbon.com/python/data_wrangling/pandas_join_merge_dataframe/\n",
    "\n",
    "tweets_df = pd.merge(tweets_df, sent_df, left_on = 'Tweet Number', right_on = 'Tweet Number')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a column to the 'temp_mod_df' dataframe with a label indicating whether the sentiment is positive or negative:\n",
    "# Source: https://stackoverflow.com/questions/26830752/making-new-column-in-pandas-dataframe-based-on-filter\n",
    "\n",
    "tweets_df['Sent_label'] = tweets_df['Sentiment'] >= 0\n",
    "\n",
    "# Replace all True/False boolean values with their respective labels ('Positive' or 'Negative'):\n",
    "# Source: https://stackoverflow.com/questions/23307301/pandas-replacing-column-values-in-dataframe\n",
    "\n",
    "tweets_df.Sent_label.replace([True, False], ['Positive', 'Negative'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet Number</th>\n",
       "      <th>Twitter Name</th>\n",
       "      <th>Twitter Handle (username)</th>\n",
       "      <th>Date and Time</th>\n",
       "      <th>User-specified Location</th>\n",
       "      <th>Number of Followers</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sent_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Michael Coleman</td>\n",
       "      <td>Colemans1</td>\n",
       "      <td>2020-04-09 19:18:17</td>\n",
       "      <td>London</td>\n",
       "      <td>1198</td>\n",
       "      <td>BBC News - #Coronavirus: Ofcom formally probes David Icke TV interview https://t.co/dBc20GHUks.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dan Currie</td>\n",
       "      <td>poeboston</td>\n",
       "      <td>2020-04-09 19:18:17</td>\n",
       "      <td>Boston</td>\n",
       "      <td>1623</td>\n",
       "      <td>The coronavirus outbreak is part of the climate change crisis @AJEnglish  https://t.co/PnCfwmRGFZ via @AJEnglish &amp;gt; #bospoli #mapoli #capitalism #publichealth #environment #climatechange #covid19 #coronavirus #pandemic.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet Number     Twitter Name Twitter Handle (username)  \\\n",
       "0  0             Michael Coleman  Colemans1                  \n",
       "1  1             Dan Currie       poeboston                  \n",
       "\n",
       "        Date and Time User-specified Location  Number of Followers  \\\n",
       "0 2020-04-09 19:18:17  London                  1198                  \n",
       "1 2020-04-09 19:18:17  Boston                  1623                  \n",
       "\n",
       "                                                                                                                                                                                                                           Tweet  \\\n",
       "0  BBC News - #Coronavirus: Ofcom formally probes David Icke TV interview https://t.co/dBc20GHUks.                                                                                                                                 \n",
       "1  The coronavirus outbreak is part of the climate change crisis @AJEnglish  https://t.co/PnCfwmRGFZ via @AJEnglish &gt; #bospoli #mapoli #capitalism #publichealth #environment #climatechange #covid19 #coronavirus #pandemic.   \n",
       "\n",
       "   Sentiment Sent_label  \n",
       "0  0.0        Positive   \n",
       "1  0.0        Positive   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) iii) Classification Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the training/test data set:\n",
    "# Note: Sample tweets should be in first column and corresponding classification (category) should be in second column.\n",
    "\n",
    "train_df = pd.read_csv('filepath/filename.csv') # Read in the sample data that is used to train the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here's a good rundown of how coronavirus is affecting agriculture and food distribution, ICYMI.\\n\\n#coronavirus #economy https://t.co/H07NGkUKcC</td>\n",
       "      <td>Advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you are trapped with an abuser during social isolation, find resources on how to get help here: https://t.co/9j9wAQ4oJH. #COVID19 #Coronavirus @Gothamist</td>\n",
       "      <td>Advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus: Half of all confirmed cases worldwide are now in Europe #Coronavirus https://t.co/nG3Hht13Hf</td>\n",
       "      <td>News coverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@barbarafriesen I was telling friends &amp;amp; family to wear masks 3 weeks ago and these top doctors were essentially saying I was a quack. Now one of them has #coronavirus. You damn right I’ll call them out on this screwup.</td>\n",
       "      <td>Blame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keeping Your Employees and Customers Safe. Learn more about our #Coronavirus Disinfection Services here: https://t.co/seS7flf7P7 https://t.co/CwUuXpeoeo</td>\n",
       "      <td>Advice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                            Tweet  \\\n",
       "0  Here's a good rundown of how coronavirus is affecting agriculture and food distribution, ICYMI.\\n\\n#coronavirus #economy https://t.co/H07NGkUKcC                                                                                 \n",
       "1  If you are trapped with an abuser during social isolation, find resources on how to get help here: https://t.co/9j9wAQ4oJH. #COVID19 #Coronavirus @Gothamist                                                                     \n",
       "2  Coronavirus: Half of all confirmed cases worldwide are now in Europe #Coronavirus https://t.co/nG3Hht13Hf                                                                                                                        \n",
       "3  @barbarafriesen I was telling friends &amp; family to wear masks 3 weeks ago and these top doctors were essentially saying I was a quack. Now one of them has #coronavirus. You damn right I’ll call them out on this screwup.   \n",
       "4  Keeping Your Employees and Customers Safe. Learn more about our #Coronavirus Disinfection Services here: https://t.co/seS7flf7P7 https://t.co/CwUuXpeoeo                                                                         \n",
       "\n",
       "        Category  \n",
       "0  Advice         \n",
       "1  Advice         \n",
       "2  News coverage  \n",
       "3  Blame          \n",
       "4  Advice         "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean the training/test data set:\n",
    "\n",
    "# Remove non-ASCII characters from 'Tweet' column in 'tweets_df' dataframe:\n",
    "\n",
    "# Sources: \n",
    "\n",
    "# i) https://www.quora.com/How-do-I-remove-non-ASCII-characters-e-g-%C3%90%C2%B1%C2%A7%E2%80%A2-%C2%B5%C2%B4%E2%80%A1%C5%BD%C2%AE%C2%BA%C3%8F%C6%92%C2%B6%C2%B9-from-texts-in-Panda%E2%80%99s-DataFrame-columns\n",
    "# ii) https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20\n",
    "\n",
    "# function to remove non-ASCII\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    return ''.join(i for i in text if ord(i)<128).encode('utf-8')\n",
    " \n",
    "train_df['Tweet'] = train_df['Tweet'].apply(remove_non_ascii)\n",
    "\n",
    "\n",
    "# Punctuate each comment with a full-stop (\".\"):\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/20025882/append-string-to-the-start-of-each-value-in-a-said-column-of-a-pandas-dataframe\n",
    "\n",
    "counter = 0\n",
    "\n",
    "while counter < len(train_df):\n",
    "    if train_df['Tweet'][counter][-1] != '.':\n",
    "        train_df.loc[counter, 'Tweet'] = train_df['Tweet'][counter] + '.'\n",
    "    counter = counter + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a train-test data set and thereafter create a learning model to classify the test data set using the \n",
    "# Stochastic Gradient Descent classifier:\n",
    "\n",
    "train_array = train_df.as_matrix()    # Convert the 'tweets_df' dataframe to an array\n",
    "\n",
    "X = train_array[:, 0]    # Assign all the data in the first column of 'train_array' to X\n",
    "Y = train_array[:, 1]    # Assign all the data in the second column of 'train_array' to Y\n",
    "\n",
    "# Specify the parameters of the training data set and the test data set. 'test_size = 0.4' refers to the test data set \n",
    "# comprising 40% of the entire data set.\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4, random_state = 42)    \n",
    "\n",
    "# Specify the parameters of the classifier model. Use the English 'stop words' list to filter out words like 'the', \n",
    "# 'is', 'of', etc. and use the Stochastic Gradient Descent classifier for the classification task. \n",
    "\n",
    "tweet_clf = Pipeline([('vect', CountVectorizer(stop_words = 'english')), ('tfidf', TfidfTransformer()), ('clf-sgd', SGDClassifier(loss = 'hinge', alpha = 1e-3, n_iter = 5, random_state = 42))])    \n",
    "\n",
    "tweet_clf = tweet_clf.fit(X_train, Y_train)    # Fit the training data to the classifier model.\n",
    "\n",
    "predicted = tweet_clf.predict(X_test)    # Predict each classification value for the data in the test set.\n",
    "\n",
    "# Summary of above variables:\n",
    "\n",
    "# 'X_train' = refers to the tweets in the training set \n",
    "# 'Y_train' = refers to the manually-labeled categories in the training set\n",
    "# 'X_test' = refers to the tweets in the test set\n",
    "# 'Y_test' = refers to the manually-labeled categories in the test set\n",
    "# 'predicted' = refers to the predicted categories that were predicted against the 'X_test' test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy of classification model: ', 40.0, '%')\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy of the classification model based on the test set:\n",
    "\n",
    "# Specifically, check how many predicted values corresponded to the actual values in the test set\n",
    "# and then get the mean of these values. This provides an indicator of how accurate\n",
    "# the classifier is for the given set of test data (this is presented as a percentage):\n",
    "\n",
    "print(\"Accuracy of classification model: \", float(np.mean(predicted == Y_test) * 100), \"%\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, run the classifier on the unclassified (new) tweets:\n",
    "\n",
    "tweets_list = tweets_df['Tweet'].tolist()   # Convert the data in the 'Comment' column of the 'content_df' dataframe to a list.\n",
    "tweets_array = np.asarray(tweets_list)    # Convert list into array.\n",
    "tweets_classd_array = tweet_clf.predict(tweets_array)    # Classify new tweets contained in array using the\n",
    "                                                         # tweet classifier ('tweet_clf') to predict the classification labels\n",
    "\n",
    "tweets_classd_df = pd.DataFrame(tweets_classd_array, columns=['Category'])   # Convert array containing classification labels\n",
    "                                                                             # into dataframe and specify column name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally, merge the original tweets dataframe with the classified tweets dataframe:\n",
    "\n",
    "tweets_merged_df = pd.merge(tweets_df, tweets_classd_df, left_index = True, right_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet Number</th>\n",
       "      <th>Twitter Name</th>\n",
       "      <th>Twitter Handle (username)</th>\n",
       "      <th>Date and Time</th>\n",
       "      <th>User-specified Location</th>\n",
       "      <th>Number of Followers</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sent_label</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Michael Coleman</td>\n",
       "      <td>Colemans1</td>\n",
       "      <td>2020-04-09 19:18:17</td>\n",
       "      <td>London</td>\n",
       "      <td>1198</td>\n",
       "      <td>BBC News - #Coronavirus: Ofcom formally probes David Icke TV interview https://t.co/dBc20GHUks.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>News coverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dan Currie</td>\n",
       "      <td>poeboston</td>\n",
       "      <td>2020-04-09 19:18:17</td>\n",
       "      <td>Boston</td>\n",
       "      <td>1623</td>\n",
       "      <td>The coronavirus outbreak is part of the climate change crisis @AJEnglish  https://t.co/PnCfwmRGFZ via @AJEnglish &amp;gt; #bospoli #mapoli #capitalism #publichealth #environment #climatechange #covid19 #coronavirus #pandemic.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>News coverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Julie Collins</td>\n",
       "      <td>CollinsAtl</td>\n",
       "      <td>2020-04-09 19:18:14</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2784</td>\n",
       "      <td>My daily visit with her, she remains a beacon of hope and health #coronavirus statueoflibertynyc #LadyLiberty #NYCStrong #golegsgo @ New York, New York https://t.co/EaHoPqcBVi.</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>Positive</td>\n",
       "      <td>News coverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>amit kumar rai</td>\n",
       "      <td>talk2amit</td>\n",
       "      <td>2020-04-09 19:18:13</td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td>Sweden took actions at the right time but not adequately..only if they would have enforced social distancing .. government should have not trusted people ..the count would have been lower.. maybe they wanted to save on the pension money #coronavirus #COVID19SWEDEN.</td>\n",
       "      <td>0.159524</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Blame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hakim Bellamy</td>\n",
       "      <td>HakimBe</td>\n",
       "      <td>2020-04-09 19:18:13</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>4424</td>\n",
       "      <td>@shaunking We knew there winds of change were on the horizon, \"weather\" political or literal...it was going to be revolution or evolution. Apparently, we elected the latter. #Coronavirus #COVID19 #COVID19forPresident #PrimaryElection #GeneralElection.</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>Positive</td>\n",
       "      <td>News coverage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet Number     Twitter Name Twitter Handle (username)  \\\n",
       "0  0             Michael Coleman  Colemans1                  \n",
       "1  1             Dan Currie       poeboston                  \n",
       "2  2             Julie Collins    CollinsAtl                 \n",
       "3  3             amit kumar rai   talk2amit                  \n",
       "4  4             Hakim Bellamy    HakimBe                    \n",
       "\n",
       "        Date and Time User-specified Location  Number of Followers  \\\n",
       "0 2020-04-09 19:18:17  London                  1198                  \n",
       "1 2020-04-09 19:18:17  Boston                  1623                  \n",
       "2 2020-04-09 19:18:14  New York, NY            2784                  \n",
       "3 2020-04-09 19:18:13                          32                    \n",
       "4 2020-04-09 19:18:13  Albuquerque, NM         4424                  \n",
       "\n",
       "                                                                                                                                                                                                                                                                       Tweet  \\\n",
       "0  BBC News - #Coronavirus: Ofcom formally probes David Icke TV interview https://t.co/dBc20GHUks.                                                                                                                                                                             \n",
       "1  The coronavirus outbreak is part of the climate change crisis @AJEnglish  https://t.co/PnCfwmRGFZ via @AJEnglish &gt; #bospoli #mapoli #capitalism #publichealth #environment #climatechange #covid19 #coronavirus #pandemic.                                               \n",
       "2  My daily visit with her, she remains a beacon of hope and health #coronavirus statueoflibertynyc #LadyLiberty #NYCStrong #golegsgo @ New York, New York https://t.co/EaHoPqcBVi.                                                                                            \n",
       "3  Sweden took actions at the right time but not adequately..only if they would have enforced social distancing .. government should have not trusted people ..the count would have been lower.. maybe they wanted to save on the pension money #coronavirus #COVID19SWEDEN.   \n",
       "4  @shaunking We knew there winds of change were on the horizon, \"weather\" political or literal...it was going to be revolution or evolution. Apparently, we elected the latter. #Coronavirus #COVID19 #COVID19forPresident #PrimaryElection #GeneralElection.                 \n",
       "\n",
       "   Sentiment Sent_label       Category  \n",
       "0  0.000000   Positive   News coverage  \n",
       "1  0.000000   Positive   News coverage  \n",
       "2  0.090909   Positive   News coverage  \n",
       "3  0.159524   Positive   Blame          \n",
       "4  0.016667   Positive   News coverage  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save 'tweets_merged_df' dataframe to a csv file:\n",
    "\n",
    "tweets_merged_df.to_csv(\"filepath/filename.csv\", encoding = 'utf-8', index = False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dataframe featuring the frequencies of each category:\n",
    "\n",
    "freq_series = tweets_classd_df.Category.value_counts()    # Create a series featuring the frequency of counts for each \n",
    "                                                                # classification.\n",
    "    \n",
    "freq_df = pd.DataFrame(freq_series)    # Convert the frequency of counts into a dataframe (for easy manipulation).\n",
    "\n",
    "freq_df.reset_index(level = 0, inplace = True)    # Reset the index of the dataframe so that you can use the \n",
    "                                                  # classification labels in a separate column.\n",
    "    \n",
    "freq_df.columns = [\"Category\", \"Frequency\"]    # Rename the columns of the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>News coverage</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advice</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Humour</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Appreciation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blame</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Self-promotion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category  Frequency\n",
       "0  News coverage   81       \n",
       "1  Advice          6        \n",
       "2  Humour          4        \n",
       "3  Appreciation    3        \n",
       "4  Blame           3        \n",
       "5  Self-promotion  2        \n",
       "6  Spam            1        "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save 'freq_df' dataframe to a csv file:\n",
    "\n",
    "freq_df.to_csv(\"filepath/filename.csv\", encoding = 'utf-8', index = False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
